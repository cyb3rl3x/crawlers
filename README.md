# Crawlers

Webcrawlers são programas criados para navegar entre páginas web, coletando e analisando seu conteúdo.
Os programas aqui listados foram criados para coleta de dados de diferentes fontes e geração de bases de dados para alimentar algoritmos de aprendizagem de máquina.
